{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "post-quantization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "nZbeZmN4N5J4"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as tf \n",
        "import tensorflow as tf1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lenet is the first Neural Network model to be implemented for the Computer Vision task, but it is useful for the grayscale images. It is used for the bank system to identify the handwritten digits. "
      ],
      "metadata": {
        "id": "KJc-obF5QzvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture of LeNet"
      ],
      "metadata": {
        "id": "v7z4CpW3OEOo"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = tf.Sequential()"
      ],
      "metadata": {
        "id": "ornY5F_pOSTw"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Input(shape = (28, 28, 1))\n",
        ")"
      ],
      "metadata": {
        "id": "hybvvItVOWLN"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Conv2D(\n",
        "        kernel_size = (5, 5), strides = (1, 1), activation = 'relu', filters = 6\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "wWPoHEcjO57q"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.AveragePooling2D(pool_size = (2, 2), strides = (2, 2))\n",
        ")"
      ],
      "metadata": {
        "id": "C8Lq9UUsPWmT"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Conv2D(\n",
        "        kernel_size = (5, 5), strides = (1, 1), activation = 'relu', filters = 16\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "fSZLg1zLPLBF"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.AveragePooling2D(pool_size = (2, 2), strides = (2, 2))\n",
        ")"
      ],
      "metadata": {
        "id": "AkLxkXufPU-z"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Flatten()\n",
        ")"
      ],
      "metadata": {
        "id": "oLQ0YUjePVPd"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Dense(units = 120, activation = 'relu')\n",
        ")"
      ],
      "metadata": {
        "id": "TTocLT2WPVb2"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Dense(units = 84, activation = 'relu')\n",
        ")"
      ],
      "metadata": {
        "id": "-8sdMcedPVlJ"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Dense(units = 10,)\n",
        ")"
      ],
      "metadata": {
        "id": "CnzccPRePVvA"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ_JMfcsQWZc",
        "outputId": "d9e7a5f8-3462-4788-f02c-061324d4f0db"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_10 (Avera  (None, 12, 12, 6)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " average_pooling2d_11 (Avera  (None, 4, 4, 16)         0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = tf.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n"
      ],
      "metadata": {
        "id": "vPmBCKfwcN1K"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.compile(loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True), metrics=[tf.metrics.SparseCategoricalAccuracy()], optimizer = 'adam')"
      ],
      "metadata": {
        "id": "__h4JBo8RNwW"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lenet_model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSNaszAVT8aP",
        "outputId": "132c65f3-efa2-4e4a-f7a2-b80d82b482e0"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2248 - sparse_categorical_accuracy: 0.9316 - val_loss: 0.0764 - val_sparse_categorical_accuracy: 0.9775\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9763 - val_loss: 0.0582 - val_sparse_categorical_accuracy: 0.9799\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.0584 - val_sparse_categorical_accuracy: 0.9812\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0445 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.0518 - val_sparse_categorical_accuracy: 0.9836\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0313 - val_sparse_categorical_accuracy: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uIyE4VKcT8em"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nQMsdlLgT8oO"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r2BCQST9T8tp"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use the model of lenet as a teacher and we are going to create a student model with the knowledge of the teacher "
      ],
      "metadata": {
        "id": "yEkTCOMMXHOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.save('lenet.h5')\n"
      ],
      "metadata": {
        "id": "Y1zbaiHPXSsU"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "(os.stat('/content/lenet.h5').st_size / 1024)/1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDLC_rpAXjSy",
        "outputId": "7349c869-663d-40f4-da6f-d0010640c8ea"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5589599609375"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not a Quite big model, but this is enough for the demonstration\n"
      ],
      "metadata": {
        "id": "FoAlQvX6YAU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student = tf.Sequential(\n",
        "    [\n",
        "        tf.layers.Input(shape=(28, 28, 1)),\n",
        "        tf.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        tf.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        tf.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        tf.layers.Flatten(),\n",
        "        tf.layers.Dense(10),\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "8lvPWLWxYGlm"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of the model\n",
        "\n",
        "student_copy = tf.models.clone_model(student)"
      ],
      "metadata": {
        "id": "auxWVY_WYHEg"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model summary of the student\n",
        "\n",
        "\n",
        "student.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvdY9Fw-YHJv",
        "outputId": "18bd6f87-b593-4e2b-a576-db3b38606431"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_23 (Conv2D)          (None, 14, 14, 16)        160       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 7, 7, 32)          4640      \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                15690     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,490\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Wise, Teacher Model has a 60k parameters, Student has a 20k parameters. So there is some difference in the number of parameter between the teacher and the student. \n",
        "We are going to use the distiller cklass which is defined in keras. https://keras.io/examples/vision/knowledge_distillation/ . This is the link for the example of knowledge distillation, take a look at it. This is created based on the example from the keras offical page"
      ],
      "metadata": {
        "id": "dmcR0WV-Y7SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(tf.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf1.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf1.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf1.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "nr62Wcw2YHOZ"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(student=student, teacher=lenet_model)\n",
        "distiller.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(x_train, y_train, epochs=3)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHTta7jHY5WY",
        "outputId": "275d7771-e95a-416c-a321-0e514c74ae32"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 27s 14ms/step - sparse_categorical_accuracy: 0.9255 - student_loss: 0.2530 - distillation_loss: 0.0461\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 26s 14ms/step - sparse_categorical_accuracy: 0.9688 - student_loss: 0.1020 - distillation_loss: 0.0233\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 25s 13ms/step - sparse_categorical_accuracy: 0.9744 - student_loss: 0.0831 - distillation_loss: 0.0202\n",
            "313/313 [==============================] - 1s 4ms/step - sparse_categorical_accuracy: 0.9779 - student_loss: 0.0670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9779000282287598, 0.0018058405257761478]"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train student as doen usually\n",
        "student_copy.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate student trained from scratch.\n",
        "student_copy.fit(x_train, y_train, epochs=3)\n",
        "student_copy.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEXk7pyHY5dD",
        "outputId": "527715c1-1bed-485d-ff30-723da89bd842"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9340\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9717\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9761\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0636371374130249, 0.9789000153541565]"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Both the student from scratch model and distilled model provides the similar result. But this is not the case in the complex dataset like a image \n",
        "# dataset, classication, object detection, in those tasks, knowledge distillation performs well"
      ],
      "metadata": {
        "id": "ssQjHuoOY6D_"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/lenet.h5')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0itNeYrggTmT",
        "outputId": "3c61c228-e881-4f22-945a-7a4b035065ca"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5589599609375"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting tf model into tf-lite model \n",
        "# step1 : Create a convertor\n",
        "# Extension of tf-lite model is .tflite\n",
        "\n",
        "tflite_filename = \"tflite-model.tflite\"\n",
        "\n",
        "# This will convert our model into a tflite model. We defined the class object, inorder to convert, we need to call the method .convert\n",
        "tflite_convertor = tf1.lite.TFLiteConverter.from_keras_model(lenet_model)\n",
        "tflite_model = tflite_convertor.convert()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUtOGFDuiuir",
        "outputId": "d8d890c8-c409-42ec-f6c9-c38236585cb8"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7dyjgy5e/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7dyjgy5e/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open(tflite_filename, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELAYAYLVjKkr",
        "outputId": "c02057d4-10d3-4ab1-be63-f3abc27067ed"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180988"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/tflite-model.tflite')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVCQXaPgjKq6",
        "outputId": "5ede50d2-db84-4976-ed95-05e8f4ca6aa8"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17260360717773438"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Post Quantization ----> This will even make our model size smaller "
      ],
      "metadata": {
        "id": "fRdXRQgZjKxO"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_convertor = tf1.lite.TFLiteConverter.from_keras_model(lenet_model)\n",
        "\n",
        "tflite_convertor.optimizations = [tf1.lite.Optimize.DEFAULT]\n",
        "\n",
        "\n",
        "tflite_quant_model = tflite_convertor.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THcg3OcjrORT",
        "outputId": "7da67705-9dd4-4b2d-f6ce-f203a7dbb2fa"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp82uxt25q/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp82uxt25q/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantizered_filename = 'quantizered_model.tflite'\n",
        "\n",
        "open(quantizered_filename, \"wb\").write(tflite_quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6Vu47arPAZ",
        "outputId": "b212b87f-4a3c-442e-e58d-954d7ac2e7fb"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52064"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/quantizered_model.tflite')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El4_CPterPEc",
        "outputId": "fcaf4616-c35e-489f-fdde-264f3bc34e3d"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.049652099609375"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# But when we convert the tf model into tf-lite model, this will reduce the accuracy of the model by little\n",
        "\n",
        "# And also, when we use quantizer optimization in the tf-lite, it further decreases the accuracy of the model, this is tradeoff of accuracy - size of \n",
        "# the model."
      ],
      "metadata": {
        "id": "SKCVi57HrPKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1fMxq8OnrPRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}