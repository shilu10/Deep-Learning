{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv2dtranspose_vs_upsampling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hhZaJ1uDk1eO"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as tf \n",
        "import numpy as np \n",
        "import tensorflow as tf1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.arange(12)\n",
        "tensor_3d = tf1.Variable(numpy_array)\n",
        "tensor_3d = tf1.reshape(tensor_3d, (1, 2, 2, 3))\n",
        "tensor_3d = tf1.cast(tensor_3d, 'float32')"
      ],
      "metadata": {
        "id": "D_iN-szqo3Cf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Difference Between Conv2DTranspose and Upsampling ?**\n",
        "\n",
        "Both are used for upsampling the matrix, both uses a different method to do a upsampling\n",
        "\n",
        "**Conv2DTranspose :**  \n",
        "Normal Convolution operation beteee the feature map and the kernel but in the different way. It takes more time for the computation. It is used in the       **UNET**for Image Segmentation\n",
        "\n",
        "**UpSampling :** \n",
        "\n",
        "It just pick the values from the nereast pixel and create a new upsampled matrix. It advantage is that it computation is cheaper. It is used in the **AutoEncoders** for Reduction of Dimensionality"
      ],
      "metadata": {
        "id": "rqC6p2sny8x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.layers.Conv2DTranspose(kernel_size = (3, 3), filters = 3, padding = 'same', strides = (2, 2))(tensor_3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC6fGyjxo3vG",
        "outputId": "45973d45-c4d1-4543-d124-324c9bd137af"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 4, 3), dtype=float32, numpy=\n",
              "array([[[[ 0.8626628 ,  0.48634994, -0.5547034 ],\n",
              "         [ 0.5048387 ,  0.3367303 , -0.51814616],\n",
              "         [ 3.7469888 , -0.10757887, -1.0595675 ],\n",
              "         [ 1.7484478 ,  1.0347728 , -0.47677183]],\n",
              "\n",
              "        [[-0.63172096,  0.6909574 ,  0.8221617 ],\n",
              "         [ 0.27613145, -0.07098261, -0.07932958],\n",
              "         [-1.4420178 ,  1.8672435 ,  1.0048254 ],\n",
              "         [ 1.7169793 ,  0.2495481 , -0.4736556 ]],\n",
              "\n",
              "        [[ 4.9307346 , -0.7583957 , -1.7704493 ],\n",
              "         [ 3.180777  ,  1.3953294 , -0.55090976],\n",
              "         [ 9.218759  , -2.6948667 , -0.64025116],\n",
              "         [ 5.207037  ,  0.94250476, -1.4328058 ]],\n",
              "\n",
              "        [[-3.1487575 ,  3.4718838 ,  2.1066236 ],\n",
              "         [ 3.1578271 ,  0.57007873, -0.8679817 ],\n",
              "         [-1.1023927 ,  4.5587664 ,  0.93899596],\n",
              "         [ 4.598675  ,  0.8906095 , -1.2623076 ]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaped the 2 * 2 * 3 image into 4 * 4 * 3, basically upsampled using the Conv2dTranspose, this is used in unet for Image segmentation\n",
        " "
      ],
      "metadata": {
        "id": "XOBTqryOvO0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.layers.UpSampling2D(size = (2, 2))(tensor_3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RpfuyBEo3yo",
        "outputId": "915bc009-bf06-4d7c-c2ae-a34de1eac0a1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 4, 3), dtype=float32, numpy=\n",
              "array([[[[ 0.,  1.,  2.],\n",
              "         [ 0.,  1.,  2.],\n",
              "         [ 3.,  4.,  5.],\n",
              "         [ 3.,  4.,  5.]],\n",
              "\n",
              "        [[ 0.,  1.,  2.],\n",
              "         [ 0.,  1.,  2.],\n",
              "         [ 3.,  4.,  5.],\n",
              "         [ 3.,  4.,  5.]],\n",
              "\n",
              "        [[ 6.,  7.,  8.],\n",
              "         [ 6.,  7.,  8.],\n",
              "         [ 9., 10., 11.],\n",
              "         [ 9., 10., 11.]],\n",
              "\n",
              "        [[ 6.,  7.,  8.],\n",
              "         [ 6.,  7.,  8.],\n",
              "         [ 9., 10., 11.],\n",
              "         [ 9., 10., 11.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaped the 2 * 2 * 3 image into 4 * 4 * 3, basically upsampled using the UpSampling, this is used in unet for Image segmentation\n",
        " "
      ],
      "metadata": {
        "id": "ecri8V3ky3en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EyTWeT06o337"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GeJwNntko391"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PNPrgXMLo4CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LKYP7xTOo4Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cCVhjgINo4Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mk3g2SCio4PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sgDfMi_Yo4VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sLXh9Vp3o4bj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}