{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantized_aware_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nZbeZmN4N5J4"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as tf \n",
        "import tensorflow as tf1\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lenet is the first Neural Network model to be implemented for the Computer Vision task, but it is useful for the grayscale images. It is used for the bank system to identify the handwritten digits. "
      ],
      "metadata": {
        "id": "KJc-obF5QzvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture of LeNet"
      ],
      "metadata": {
        "id": "v7z4CpW3OEOo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = tf.Sequential()"
      ],
      "metadata": {
        "id": "ornY5F_pOSTw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Input(shape = (28, 28, 1))\n",
        ")"
      ],
      "metadata": {
        "id": "hybvvItVOWLN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Conv2D(\n",
        "        kernel_size = (5, 5), strides = (1, 1), activation = 'relu', filters = 6\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "wWPoHEcjO57q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.AveragePooling2D(pool_size = (2, 2), strides = (2, 2))\n",
        ")"
      ],
      "metadata": {
        "id": "C8Lq9UUsPWmT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Conv2D(\n",
        "        kernel_size = (5, 5), strides = (1, 1), activation = 'relu', filters = 16\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "fSZLg1zLPLBF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.AveragePooling2D(pool_size = (2, 2), strides = (2, 2))\n",
        ")"
      ],
      "metadata": {
        "id": "AkLxkXufPU-z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Flatten()\n",
        ")"
      ],
      "metadata": {
        "id": "oLQ0YUjePVPd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Dense(units = 120, activation = 'relu')\n",
        ")"
      ],
      "metadata": {
        "id": "TTocLT2WPVb2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Dense(units = 84, activation = 'relu')\n",
        ")"
      ],
      "metadata": {
        "id": "-8sdMcedPVlJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.add(\n",
        "    tf.layers.Dense(units = 10,)\n",
        ")"
      ],
      "metadata": {
        "id": "CnzccPRePVvA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ_JMfcsQWZc",
        "outputId": "9162d878-4bd8-464c-9a1c-6701d376f83f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 12, 12, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 4, 4, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = tf.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n"
      ],
      "metadata": {
        "id": "vPmBCKfwcN1K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.compile(loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True), metrics=[tf.metrics.SparseCategoricalAccuracy()], optimizer = 'adam')"
      ],
      "metadata": {
        "id": "__h4JBo8RNwW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lenet_model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSNaszAVT8aP",
        "outputId": "47db451d-a1d2-4f9b-bfd6-8f4830576dc9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 26s 13ms/step - loss: 0.2271 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.0752 - val_sparse_categorical_accuracy: 0.9760\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9758 - val_loss: 0.0639 - val_sparse_categorical_accuracy: 0.9814\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0519 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9862 - val_loss: 0.0501 - val_sparse_categorical_accuracy: 0.9842\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.0347 - val_sparse_categorical_accuracy: 0.9885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uIyE4VKcT8em"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nQMsdlLgT8oO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r2BCQST9T8tp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use the model of lenet as a teacher and we are going to create a student model with the knowledge of the teacher "
      ],
      "metadata": {
        "id": "yEkTCOMMXHOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.save('lenet.h5')\n"
      ],
      "metadata": {
        "id": "Y1zbaiHPXSsU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "(os.stat('/content/lenet.h5').st_size / 1024)/1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDLC_rpAXjSy",
        "outputId": "fbcb716c-9858-44b7-d5f2-3bf8adb8a053"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.558868408203125"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not a Quite big model, but this is enough for the demonstration\n"
      ],
      "metadata": {
        "id": "FoAlQvX6YAU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student = tf.Sequential(\n",
        "    [\n",
        "        tf.layers.Input(shape=(28, 28, 1)),\n",
        "        tf.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        tf.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        tf.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        tf.layers.Flatten(),\n",
        "        tf.layers.Dense(10),\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "8lvPWLWxYGlm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of the model\n",
        "\n",
        "student_copy = tf.models.clone_model(student)"
      ],
      "metadata": {
        "id": "auxWVY_WYHEg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model summary of the student\n",
        "\n",
        "\n",
        "student.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvdY9Fw-YHJv",
        "outputId": "905ea2d0-09ac-4b55-d838-ba2ae3ddc977"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 16)        160       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 32)          4640      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                15690     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,490\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Wise, Teacher Model has a 60k parameters, Student has a 20k parameters. So there is some difference in the number of parameter between the teacher and the student. \n",
        "We are going to use the distiller cklass which is defined in keras. https://keras.io/examples/vision/knowledge_distillation/ . This is the link for the example of knowledge distillation, take a look at it. This is created based on the example from the keras offical page"
      ],
      "metadata": {
        "id": "dmcR0WV-Y7SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(tf.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf1.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf1.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf1.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "nr62Wcw2YHOZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Transfer(Distillation)"
      ],
      "metadata": {
        "id": "mRJ0P0_2MiiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(student=student, teacher=lenet_model)\n",
        "distiller.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(x_train, y_train, epochs=3)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHTta7jHY5WY",
        "outputId": "59bcd31e-78de-44f4-a10a-233201c66e05"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 24s 12ms/step - sparse_categorical_accuracy: 0.9202 - student_loss: 0.2667 - distillation_loss: 0.0498\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 23s 12ms/step - sparse_categorical_accuracy: 0.9656 - student_loss: 0.1128 - distillation_loss: 0.0264\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 23s 12ms/step - sparse_categorical_accuracy: 0.9735 - student_loss: 0.0836 - distillation_loss: 0.0219\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9775 - student_loss: 0.0710\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9775000214576721, 0.002221818780526519]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train student as doen usually\n",
        "student_copy.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate student trained from scratch.\n",
        "student_copy.fit(x_train, y_train, epochs=3)\n",
        "student_copy.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEXk7pyHY5dD",
        "outputId": "76b34c91-8888-4299-fe60-59dab4350faa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2512 - sparse_categorical_accuracy: 0.9247\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9704\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9758\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07117975503206253, 0.9764999747276306]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Both the student from scratch model and distilled model provides the similar result. But this is not the case in the complex dataset like a image \n",
        "# dataset, classication, object detection, in those tasks, knowledge distillation performs well"
      ],
      "metadata": {
        "id": "ssQjHuoOY6D_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/lenet.h5')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0itNeYrggTmT",
        "outputId": "1dfb2f4d-95cf-4253-e71d-4335b8ffc12c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.558868408203125"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-Lite Model Technique"
      ],
      "metadata": {
        "id": "g41_BpV6Mcnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting tf model into tf-lite model \n",
        "# step1 : Create a convertor\n",
        "# Extension of tf-lite model is .tflite\n",
        "\n",
        "tflite_filename = \"tflite-model.tflite\"\n",
        "\n",
        "# This will convert our model into a tflite model. We defined the class object, inorder to convert, we need to call the method .convert\n",
        "tflite_convertor = tf1.lite.TFLiteConverter.from_keras_model(lenet_model)\n",
        "tflite_model = tflite_convertor.convert()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUtOGFDuiuir",
        "outputId": "7bd6b86b-ff1b-4f21-ab45-73e762150952"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp79wjtmt3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open(tflite_filename, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELAYAYLVjKkr",
        "outputId": "35eff0ea-d3f8-4928-fa6c-df8a4a608515"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180952"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/tflite-model.tflite')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVCQXaPgjKq6",
        "outputId": "9ecfd8e8-d508-47b7-80ae-658aa90f3ed4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17256927490234375"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Post Quantization ----> This will even make our model size smaller "
      ],
      "metadata": {
        "id": "fRdXRQgZjKxO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Quantization Technique"
      ],
      "metadata": {
        "id": "z0RoTwf4MW4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_convertor = tf1.lite.TFLiteConverter.from_keras_model(lenet_model)\n",
        "\n",
        "tflite_convertor.optimizations = [tf1.lite.Optimize.DEFAULT]\n",
        "\n",
        "\n",
        "tflite_quant_model = tflite_convertor.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THcg3OcjrORT",
        "outputId": "ce941998-a2a2-4290-bc49-a3850167d3d6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr_lswihw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr_lswihw/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantizered_filename = 'quantizered_model.tflite'\n",
        "\n",
        "open(quantizered_filename, \"wb\").write(tflite_quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6Vu47arPAZ",
        "outputId": "974c1191-2641-490c-d940-017ad7eccc9b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52016"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/quantizered_model.tflite')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El4_CPterPEc",
        "outputId": "772babf5-96a5-47b9-c1d4-e33e4924dd49"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0496063232421875"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization "
      ],
      "metadata": {
        "id": "1fMxq8OnrPRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f48fc2-c204-4e92-b24a-25b2784e2590"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 184 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 204 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 225 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 235 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 237 kB 20.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.21.5)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# But when we convert the tf model into tf-lite model, this will reduce the accuracy of the model by little\n",
        "\n",
        "# And also, when we use quantizer optimization in the tf-lite, it further decreases the accuracy of the model, this is tradeoff of accuracy - size of \n",
        "# the model."
      ],
      "metadata": {
        "id": "SKCVi57HrPKN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization Training Aware"
      ],
      "metadata": {
        "id": "JPuJfNzWMLg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot"
      ],
      "metadata": {
        "id": "5A_fZwpMI9QL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "id": "diDIZShJI9Ya"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_aware_model = quantize_model(lenet_model)\n",
        "\n",
        "quantized_aware_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "quantized_aware_model.fit(x_train, y_train, epochs = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CUfSxkNI9dw",
        "outputId": "6b8451f6-eccc-4b21-94fc-45534ed3e519"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 32s 16ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9904\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0252 - sparse_categorical_accuracy: 0.9916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d845fc0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_convertor = tf1.lite.TFLiteConverter.from_keras_model(quantized_aware_model)\n",
        "quantized_aware_model  = tflite_convertor.convert()\n",
        "\n",
        "\n",
        "open('quantized_aware_model.tflite', 'wb').write(quantized_aware_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPbV3cN9I9kA",
        "outputId": "c408e1cb-0093-40b9-8150-e1f5299c1864"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, flatten_1_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppy8z36_7/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppy8z36_7/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "370024"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(os.path.getsize(filename='/content/quantized_aware_model.tflite')/(1024 * 1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRd3MPEAI9tl",
        "outputId": "fe8b21a7-706c-44e0-e809-2c089c27c1ae"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35288238525390625"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BmNS4XN6I91e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GDU77fEzI98L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}